{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs Cats Redux vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/home/ubuntu/courses/deeplearning1/nbs/lesson1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/courses/deeplearning1/nbs/lesson1/data'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "LESSON_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir+'/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# current dir to search path\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "# import modules\n",
    "from utils import *\n",
    "from vgg16 import Vgg16\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation set and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "%mkdir valid\n",
    "%mkdir results\n",
    "%mkdir -p sample/train\n",
    "%mkdir -p sample/test\n",
    "%mkdir -p sample/valid\n",
    "%mkdir -p sample/results\n",
    "%mkdir -p test/unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/train\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "randomly select validation data and move to data/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(2000):\n",
    "    os.rename(shuf[i], DATA_HOME_DIR+'/valid/' + shuf[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "randomly select sample data for prototyping and copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(200):\n",
    "    copyfile(shuf[i], DATA_HOME_DIR+'/sample/train/' + shuf[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "randomly select sample validation data for prototyping and copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/valid\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(50):\n",
    "    copyfile(shuf[i], DATA_HOME_DIR+'/sample/valid/' + shuf[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize images into category folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/sample/train\n",
      "mkdir: cannot create directory 'cats': File exists\n",
      "mkdir: cannot create directory 'dogs': File exists\n",
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/sample/valid\n",
      "mkdir: cannot create directory 'cats': File exists\n",
      "mkdir: cannot create directory 'dogs': File exists\n",
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/valid\n",
      "mkdir: cannot create directory 'cats': File exists\n",
      "mkdir: cannot create directory 'dogs': File exists\n",
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/train\n",
      "mkdir: cannot create directory 'cats': File exists\n",
      "mkdir: cannot create directory 'dogs': File exists\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR/sample/train\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/\n",
    "\n",
    "%cd $DATA_HOME_DIR/sample/valid\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/\n",
    "\n",
    "%cd $DATA_HOME_DIR/valid\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/\n",
    "\n",
    "%cd $DATA_HOME_DIR/train\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data/test\n"
     ]
    }
   ],
   "source": [
    "# create an 'unknown' class for test\n",
    "%cd $DATA_HOME_DIR/test\n",
    "%mv *.jpg unknown/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/courses/deeplearning1/nbs/lesson1/data\n"
     ]
    }
   ],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "\n",
    "# Set up paths\n",
    "#path = DATA_HOME_DIR + '/'\n",
    "path = DATA_HOME_DIR + '/sample/'\n",
    "test_path = DATA_HOME_DIR + '/test/'\n",
    "results_path = DATA_HOME_DIR + '/results/'\n",
    "train_path = DATA_HOME_DIR + '/train/'\n",
    "valid_path = DATA_HOME_DIR + '/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import helper class\n",
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set constants\n",
    "batch_size = 64\n",
    "num_epochs = 3 # what is this for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# fine tune\n",
    "batches = vgg.get_batches(train_path, batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(valid_path, batch_size=batch_size*2)\n",
    "vgg.finetune(batches)\n",
    "\n",
    "# i'm guessing this is the learning rate\n",
    "vgg.model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running epoch: 0\n",
      "Epoch 1/1\n",
      "23000/23000 [==============================] - 642s - loss: 0.3769 - acc: 0.9690 - val_loss: 0.2448 - val_acc: 0.9815\n",
      "Running epoch: 1\n",
      "Epoch 1/1\n",
      "23000/23000 [==============================] - 643s - loss: 0.3400 - acc: 0.9753 - val_loss: 0.2461 - val_acc: 0.9825\n",
      "Running epoch: 2\n",
      "Epoch 1/1\n",
      "23000/23000 [==============================] - 642s - loss: 0.3476 - acc: 0.9754 - val_loss: 0.1726 - val_acc: 0.9885\n",
      "Completed 3 fit operations\n"
     ]
    }
   ],
   "source": [
    "# fit over a few epochs\n",
    "latest_weights_filename = None\n",
    "for epoch in range(num_epochs):\n",
    "    print \"Running epoch: %d\" % epoch\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "    latest_weights_filename = 'ft%d.h5' % epoch\n",
    "    vgg.model.save_weights(results_path+latest_weights_filename)\n",
    "    \n",
    "print \"Completed %s fit operations\" % num_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "- what do the epochs represent? \n",
    "- does each epoch use all the data in batches?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batches, preds = vgg.test(test_path, batch_size=batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print preds[:5]\n",
    "\n",
    "filenames = batches.filenames\n",
    "print filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# verify classification\n",
    "from PIL import Image\n",
    "Image.open(test_path + filenames[1])\n",
    "Image.open(test_path + filenames[2])\n",
    "Image.open(test_path + filenames[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save result arrays for later\n",
    "save_array(results_path + 'test_preds.dat', preds)\n",
    "save_array(results_path + 'filenames.dat', filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg.model.load_weights(results_pathath + latest_weights_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_batches, probs = vgg.test(valid_path, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = val_batches.filenamesmes\n",
    "expected_labels = val_batches.classes # 0 or 1\n",
    "\n",
    "# round predictions to 0/1 to generate labels\n",
    "our_predictions = probs[:,0]\n",
    "our_labels = np.round(1-our_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "- what is the probs[:,0] syntax mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "# create helper function to plot images by indix in the validation set\n",
    "def plots_idx(idx, titles=None):\n",
    "    # plots is a helper function in utils.py\n",
    "    plots([image.load_img(valid_path + filenames[i]) for i in idx], titles=titles)\n",
    "    \n",
    "# number of images per view\n",
    "n_view = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. A few correct labels at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct = np.where(our_labels==expected_labels)[0]\n",
    "# why the [0] at the end?\n",
    "print \"Found %d correct labels\" % len(correct)\n",
    "idx = permutation(correct)[:n_view]\n",
    "permutations_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. A few incorrect labels at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incorrect = np.where(our_labels!=expected_labels)[0]\n",
    "print \"Found %d incorrect labels\" % len(incorrect)\n",
    "idx = permutation(incorrect)[:n_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Correct cat images with high confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_cats = np.where((our_labels==0) & (our_labels==expected_labels))[0]\n",
    "print \"Found %d confident correct cats\" % len(correct_cats)\n",
    "most_correct_cats = np.argsort(our_predictions[correct_cats])[::-1][:n_view]\n",
    "plots_idx(correct_cats[most_correct_cats], our_predictions[correct_cats][most_correct_cats])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Correct dog images with high confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_dogs = np.where((our_labels==0) & (our_labels==expected_labels))[0]\n",
    "print \"Found %d confident correct dogs\" % len(correct_dogs)\n",
    "most_correct_dogs = np.argsort(our_predictions[correct_dogs])[::-1][:n_view]\n",
    "plots_idx(correct_dogs[most_correct_dogs], our_predictions[correct_dogs][most_correct_dogs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Incorrect cat images with high confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incorrect_cats = np.where((our_labels==0) & (expected_labels!=0))[0]\n",
    "print \"Found %d incorrect cats\" % len(incorrect_cats)\n",
    "\n",
    "if len(incorrect_cats):\n",
    "    most_incorrect_cats = np.argsort(our_predictions[incorrect_cats])[::-1][:n_view]\n",
    "    plots_idx(incorrect_cats[most_incorrect_cats], our_predictions[incorrect_cats][most_incorrect_cats])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Incorrect dog images with high confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "incorrect_dogs = np.where((our_labels==0) & (expected_labels!=0))[0]\n",
    "print \"Found %d incorrect dogs\" % len(incorrect_dogs)\n",
    "\n",
    "if len(incorrect_dogs):\n",
    "    most_incorrect_dogs = np.argsort(our_predictions[incorrect_dogs])[::-1][:n_view]\n",
    "    plots_idx(incorrect_dogs[most_incorrect_dogs], our_predictions[incorrect_dogs][most_incorrect_dogs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Most uncertain labels (i.e. probability closest to 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "most_uncertain = np.argsort(np.abs(our_predictions-0.5))\n",
    "plots_idx(most_uncertain[:n_view], our_predictions[most_uncertain])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
